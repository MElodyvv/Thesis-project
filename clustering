# 1. Load the data ---------------------
file_path = r'C:\Users\86189\Desktop\UVA毕业论文\dataset\yum_train.json'

with open(file_path, 'r', encoding='utf-8') as file:
    data = json.load(file)

en_recipe_df = pd.DataFrame(data)
en_cn_recipes = en_recipe_df.loc[en_recipe_df['cuisine'] == 'chinese'].drop(columns=['cuisine'])
en_cn_recipes['ingredients'] = en_cn_recipes['ingredients'].apply(lambda x: ', '.join(x))
en_cn_recipes = en_cn_recipes.sample(n=965, random_state=42)
# print('The number of Chinese recipes in English:', len(en_cn_recipes))
# print(en_cn_recipes)

# Load Chinese-Chinese recipes (translated)
file_path = r'C:\Users\86189\Desktop\UVA毕业论文\dataset\965-en - 副本.csv'
cn_recipe_df = pd.read_csv(file_path)
cn_recipe_df['Title'] = cn_recipe_df['Title'].str.strip().str.lower()
cn_recipe_df['Ingredients'] = cn_recipe_df['Ingredients'].str.replace("'", "").str.lower()
cn_recipe_df.rename(columns={'Title': 'id'}, inplace=True)
cn_recipe_df.rename(columns={'Ingredients': 'ingredients'}, inplace=True)
cn_recipe_df['ingredients'] = cn_recipe_df['ingredients'].str.replace('[', '').str.replace(']', '')
cn_recipe_df['ingredients'] = cn_recipe_df['ingredients'].str.strip()

en_cn_recipes['cuisine_label'] = 'EN-CN'
cn_recipe_df['cuisine_label'] = 'CN-CN'
recipes_df = pd.concat([en_cn_recipes, cn_recipe_df[['id', 'ingredients', 'cuisine_label']]], axis=0, ignore_index=True)
# print(recipes_df)

from sklearn.feature_extraction.text import CountVectorizer

# Tokenize and count occurrences of words in ingredients
count_vectorizer = CountVectorizer()
bow_matrix = count_vectorizer.fit_transform(recipes_df['ingredients'])

# Convert the bag-of-words matrix to a DataFrame
bow_df = pd.DataFrame(bow_matrix.toarray(), columns=count_vectorizer.get_feature_names_out())

# Add the bag-of-words representation to the recipes DataFrame
recipes_df['bow'] = bow_df.apply(lambda x: x.to_dict(), axis=1)


# 5. One-hot encoding
vectorizer = DictVectorizer(sparse=False)
X = vectorizer.fit_transform(recipes_df['bow'].tolist())


print("Dimensionality of the one-hot encoded feature matrix:", X.shape)


# # ----------PCA
# X_embedded_pca = KernelPCA(n_components=2, kernel='cosine', n_jobs=2).fit_transform(X)
#

#
# DataFrame
# plotting_df = pd.DataFrame(data=X_embedded_pca, columns=['x', 'y'])
# plotting_df['cuisine'] = recipes_df['cuisine_label']
#
# plt.figure(figsize=(10, 6))
# sns.scatterplot(x='x', y='y', hue='cuisine', data=plotting_df, palette='viridis', legend='full')
# plt.title('PCA with Cosine Kernel')
# plt.xlabel('Principal Component 1')
# plt.ylabel('Principal Component 2')
# plt.legend(title='Cuisine')
# plt.show()

# ----------------t-SNE: t-distributed Stochastic Neighbor Embedding
# Compute Cosine Similarity Matrix
X_to_reduce = pairwise_distances(X, metric='cosine')
X_embedded_tsne = TSNE().fit_transform(X_to_reduce)

# Plotting the clusters
plt.figure(figsize=(10, 6))
sns.scatterplot(x=X_embedded_tsne[:,0], y=X_embedded_tsne[:,1], hue=recipes_df['cuisine_label'], palette='viridis', legend='full')
plt.title('t-SNE Clustering of Recipes')
plt.xlabel('t-SNE Component 1')
plt.ylabel('t-SNE Component 2')
plt.legend(title='Cuisine Label')
plt.show()
